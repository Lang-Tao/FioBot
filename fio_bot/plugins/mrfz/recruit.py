"""å…¬æ‹›æ ‡ç­¾ç»„åˆè®¡ç®—æ¨¡å—

æ ¸å¿ƒç®—æ³•ï¼šç»™å®šç”¨æˆ·é€‰æ‹©çš„æ ‡ç­¾ï¼Œè®¡ç®—æ‰€æœ‰æœ‰ä»·å€¼çš„æ ‡ç­¾ç»„åˆåŠåŒ¹é…å¹²å‘˜
"""

import itertools
import re
from typing import Optional


# ==================== æ ‡ç­¾åˆ«å/ç¼©å†™ ====================

TAG_ALIASES = {
    # èµ„è´¨ç±»
    "é«˜èµ„": "é«˜çº§èµ„æ·±å¹²å‘˜", "é«˜å§¿": "é«˜çº§èµ„æ·±å¹²å‘˜", "é«˜çº§": "é«˜çº§èµ„æ·±å¹²å‘˜", "é«˜çº§èµ„æ·±": "é«˜çº§èµ„æ·±å¹²å‘˜",
    "èµ„æ·±": "èµ„æ·±å¹²å‘˜", "èµ„å¹²": "èµ„æ·±å¹²å‘˜",
    "æœºæ¢°": "æ”¯æ´æœºæ¢°", "æ”¯æœº": "æ”¯æ´æœºæ¢°",
    # ä½ç½®ç±»
    "è¿‘æˆ˜": "è¿‘æˆ˜ä½", "è¿œç¨‹": "è¿œç¨‹ä½",
    # èŒä¸šç±»ï¼ˆç¼©å†™ â†’ å…¨ç§°ï¼‰
    "è¿‘å«": "è¿‘å«å¹²å‘˜", "ç‹™å‡»": "ç‹™å‡»å¹²å‘˜", "é‡è£…": "é‡è£…å¹²å‘˜",
    "åŒ»ç–—": "åŒ»ç–—å¹²å‘˜", "è¾…åŠ©": "è¾…åŠ©å¹²å‘˜", "æœ¯å¸ˆ": "æœ¯å¸ˆå¹²å‘˜",
    "æœ¯å£«": "æœ¯å¸ˆå¹²å‘˜",  # å¸¸è§é”™å­—
    "ç‰¹ç§": "ç‰¹ç§å¹²å‘˜", "å…ˆé”‹": "å…ˆé”‹å¹²å‘˜",
    # èƒ½åŠ›ç±»
    "å›è´¹": "è´¹ç”¨å›å¤", "è´¹å›": "è´¹ç”¨å›å¤", "æ¢å¤": "è´¹ç”¨å›å¤",
    "å¿«æ´»": "å¿«é€Ÿå¤æ´»", "å¤æ´»": "å¿«é€Ÿå¤æ´»", "å¿«é€Ÿ": "å¿«é€Ÿå¤æ´»",
    # å®Œæ•´æ ‡ç­¾çš„è‡ªèº«æ˜ å°„ï¼ˆç”¨æˆ·ç›´æ¥è¾“å…¥å®Œæ•´æ ‡ç­¾ï¼‰
    "é«˜çº§èµ„æ·±å¹²å‘˜": "é«˜çº§èµ„æ·±å¹²å‘˜",
    "èµ„æ·±å¹²å‘˜": "èµ„æ·±å¹²å‘˜",
    "æ”¯æ´æœºæ¢°": "æ”¯æ´æœºæ¢°",
    "è¿‘æˆ˜ä½": "è¿‘æˆ˜ä½", "è¿œç¨‹ä½": "è¿œç¨‹ä½",
    "è¿‘å«å¹²å‘˜": "è¿‘å«å¹²å‘˜", "ç‹™å‡»å¹²å‘˜": "ç‹™å‡»å¹²å‘˜", "é‡è£…å¹²å‘˜": "é‡è£…å¹²å‘˜",
    "åŒ»ç–—å¹²å‘˜": "åŒ»ç–—å¹²å‘˜", "è¾…åŠ©å¹²å‘˜": "è¾…åŠ©å¹²å‘˜", "æœ¯å¸ˆå¹²å‘˜": "æœ¯å¸ˆå¹²å‘˜",
    "ç‰¹ç§å¹²å‘˜": "ç‰¹ç§å¹²å‘˜", "å…ˆé”‹å¹²å‘˜": "å…ˆé”‹å¹²å‘˜",
    "æ§åœº": "æ§åœº", "çˆ†å‘": "çˆ†å‘", "æ²»ç–—": "æ²»ç–—", "æ”¯æ´": "æ”¯æ´",
    "è´¹ç”¨å›å¤": "è´¹ç”¨å›å¤", "è¾“å‡º": "è¾“å‡º", "ç”Ÿå­˜": "ç”Ÿå­˜",
    "ç¾¤æ”»": "ç¾¤æ”»", "é˜²æŠ¤": "é˜²æŠ¤", "å‡é€Ÿ": "å‡é€Ÿ", "å‰Šå¼±": "å‰Šå¼±",
    "å¿«é€Ÿå¤æ´»": "å¿«é€Ÿå¤æ´»", "ä½ç§»": "ä½ç§»", "å¬å”¤": "å¬å”¤", "å…ƒç´ ": "å…ƒç´ ",
    "æ–°æ‰‹": "æ–°æ‰‹",
}


def smart_split_tags(text: str, valid_tags: list[str]) -> list[str]:
    """
    æ™ºèƒ½åˆ†è¯ï¼šæ”¯æŒç”¨æˆ·è¾“å…¥æ— ç©ºæ ¼çš„æ ‡ç­¾è¿å†™ï¼ˆå¦‚"é«˜èµ„è¿‘å«è¾“å‡º"ï¼‰

    1. å…ˆæŒ‰åˆ†éš”ç¬¦æ‹†åˆ†
    2. å¯¹æ— æ³•ç›´æ¥è¯†åˆ«çš„é•¿æ®µï¼Œå°è¯•ä»å·²çŸ¥åˆ«å/æ ‡ç­¾ä¸­è´ªå©ªåŒ¹é…æ‹†åˆ†
    """
    # å…ˆæŒ‰å¸¸è§„åˆ†éš”ç¬¦æ‹†
    parts = re.split(r"[,ï¼Œ\s]+", text.strip())
    parts = [p.strip() for p in parts if p.strip()]

    # æ„å»ºæ‰€æœ‰å¯è¯†åˆ«çš„å…³é”®è¯ï¼ˆåˆ«å + å®Œæ•´æ ‡ç­¾ï¼‰ï¼ŒæŒ‰é•¿åº¦ä»é•¿åˆ°çŸ­æ’åº
    all_keywords = sorted(
        set(list(TAG_ALIASES.keys()) + list(valid_tags)),
        key=len,
        reverse=True,
    )

    result = []
    for part in parts:
        # å¦‚æœè¿™ä¸ªç‰‡æ®µèƒ½ç›´æ¥è¢«è¯†åˆ«ï¼ˆåœ¨åˆ«åæˆ–åˆæ³•æ ‡ç­¾ä¸­ï¼‰ï¼Œç›´æ¥ä¿ç•™
        if part in TAG_ALIASES or part in valid_tags:
            result.append(part)
            continue

        # å°è¯•è´ªå©ªæ‹†åˆ†
        remaining = part
        found_any = False
        while remaining:
            matched = False
            for kw in all_keywords:
                if remaining.startswith(kw):
                    result.append(kw)
                    remaining = remaining[len(kw):]
                    matched = True
                    found_any = True
                    break
            if not matched:
                # è·³è¿‡ä¸€ä¸ªå­—ç¬¦ç»§ç»­å°è¯•
                remaining = remaining[1:]

        # å¦‚æœå®Œå…¨æ²¡åŒ¹é…åˆ°ï¼Œä¿ç•™åŸå§‹ç‰‡æ®µè®© normalize_tags å¤„ç†
        if not found_any:
            result.append(part)

    return result


def normalize_tags(raw_tags: list[str], valid_tags: list[str]) -> list[str]:
    """
    å°†ç”¨æˆ·è¾“å…¥çš„æ ‡ç­¾æ ‡å‡†åŒ–ä¸ºåˆæ³•æ¸¸æˆæ ‡ç­¾

    Args:
        raw_tags: ç”¨æˆ·è¾“å…¥çš„åŸå§‹æ ‡ç­¾åˆ—è¡¨
        valid_tags: æ¸¸æˆä¸­æ‰€æœ‰åˆæ³•æ ‡ç­¾

    Returns:
        æ ‡å‡†åŒ–åçš„æ ‡ç­¾åˆ—è¡¨ï¼ˆå»é‡ï¼‰
    """
    result = []
    valid_set = set(valid_tags)

    for raw in raw_tags:
        raw = raw.strip()
        if not raw:
            continue

        # ä¼˜å…ˆå®Œå…¨åŒ¹é…åˆæ³•æ ‡ç­¾
        if raw in valid_set:
            if raw not in result:
                result.append(raw)
            continue

        # åˆ«åæ˜ å°„
        mapped = TAG_ALIASES.get(raw)
        if mapped and mapped in valid_set:
            if mapped not in result:
                result.append(mapped)
            continue

        # æ¨¡ç³ŠåŒ¹é…ï¼šç”¨æˆ·è¾“å…¥æ˜¯æŸä¸ªåˆæ³•æ ‡ç­¾çš„å­ä¸²
        for vt in valid_tags:
            if raw in vt:
                if vt not in result:
                    result.append(vt)
                break

    return result


# ==================== æ˜Ÿçº§æ˜¾ç¤º ====================

RARITY_STARS = {0: "â˜…", 1: "â˜…â˜…", 2: "â˜…â˜…â˜…", 3: "â˜…â˜…â˜…â˜…", 4: "â˜…â˜…â˜…â˜…â˜…", 5: "â˜…â˜…â˜…â˜…â˜…â˜…"}


def rarity_display(rarity: int) -> str:
    """å°† 0-based ç¨€æœ‰åº¦è½¬æ¢ä¸ºæ˜Ÿçº§æ˜¾ç¤º"""
    return RARITY_STARS.get(rarity, f"{rarity + 1}â˜…")


# ==================== æ ¸å¿ƒç®—æ³• ====================


def find_recruit_combinations(
    user_tags: list[str],
    operators: list[dict],
    max_combo_size: int = 3,
) -> list[dict]:
    """
    è®¡ç®—æ‰€æœ‰æœ‰ä»·å€¼çš„æ ‡ç­¾ç»„åˆåŠåŒ¹é…å¹²å‘˜

    Args:
        user_tags: ç”¨æˆ·é€‰æ‹©çš„æ ‡ç­¾ï¼ˆå·²æ ‡å‡†åŒ–ï¼‰
        operators: å¹²å‘˜æ•°æ® [{name, rarity, tags}, ...]
        max_combo_size: æœ€å¤§ç»„åˆæ ‡ç­¾æ•°ï¼ˆå…¬æ‹›æœ€å¤šé€‰ 3 ä¸ªæ ‡ç­¾ï¼‰

    Returns:
        ç»“æœåˆ—è¡¨ï¼ŒæŒ‰æœ€ä½ä¿åº•æ˜Ÿçº§ä»é«˜åˆ°ä½æ’åº
        [{"tags": [...], "operators": [{name, rarity}, ...], "min_rarity": int}, ...]
    """
    results = []

    # ç”Ÿæˆ 1~max_combo_size çš„æ‰€æœ‰æ ‡ç­¾ç»„åˆ
    for size in range(1, min(max_combo_size, len(user_tags)) + 1):
        for combo in itertools.combinations(user_tags, size):
            combo_set = set(combo)
            matched = []

            for op in operators:
                # å¹²å‘˜çš„æ ‡ç­¾é›†å¿…é¡»åŒ…å«ç»„åˆä¸­çš„æ‰€æœ‰æ ‡ç­¾
                if not combo_set.issubset(op["tags"]):
                    continue

                # 6â˜… ä¿æŠ¤ï¼šé™¤éç»„åˆä¸­æœ‰"é«˜çº§èµ„æ·±å¹²å‘˜"ï¼Œå¦åˆ™è·³è¿‡ 6â˜…
                if op["rarity"] == 5 and "é«˜çº§èµ„æ·±å¹²å‘˜" not in combo_set:
                    continue

                matched.append({"name": op["name"], "rarity": op["rarity"]})

            if not matched:
                continue

            # è®¡ç®—è¿™ä¸ªç»„åˆçš„æœ€ä½ä¿åº•ç¨€æœ‰åº¦
            min_rarity = min(m["rarity"] for m in matched)
            max_rarity = max(m["rarity"] for m in matched)

            # åªä¿ç•™é«˜ä»·å€¼ç»„åˆï¼šä¿åº• 4â˜…+ æˆ–å¿…å‡º 1â˜…ï¼ˆæ”¯æ´æœºæ¢°ï¼‰ï¼Œè·³è¿‡ 2â˜… å’Œ 3â˜…
            if min_rarity in (1, 2):
                continue

            # 1â˜… ç»„åˆä»…åœ¨"å¿…å‡º"æ—¶ä¿ç•™ï¼ˆæ‰€æœ‰åŒ¹é…å¹²å‘˜éƒ½æ˜¯ 1â˜…ï¼‰
            if min_rarity == 0:
                if max_rarity > 0:
                    continue
                matched = [m for m in matched if m["rarity"] == 0]

            # æŒ‰ç¨€æœ‰åº¦ä»é«˜åˆ°ä½æ’åºåŒ¹é…å¹²å‘˜
            matched.sort(key=lambda x: (-x["rarity"], x["name"]))

            results.append({
                "tags": list(combo),
                "operators": matched,
                "min_rarity": min_rarity,
            })

    # æŒ‰æœ€ä½ä¿åº•æ˜Ÿçº§ä»é«˜åˆ°ä½æ’åºï¼Œç›¸åŒåˆ™æŒ‰æ ‡ç­¾æ•°ä»å°‘åˆ°å¤š
    results.sort(key=lambda x: (-x["min_rarity"], len(x["tags"])))

    return results


def extract_tags_from_ocr(ocr_lines: list[str], valid_tags: list[str]) -> list[str]:
    """
    ä» OCR è¯†åˆ«ç»“æœä¸­æå–å…¬æ‹›æ ‡ç­¾

    å…¬æ‹›æˆªå›¾ä¸­çš„æ ‡ç­¾é€šå¸¸æ˜¯æ ‡å‡†çš„æ¸¸æˆæ ‡ç­¾åï¼Œç›´æ¥åšå®Œå…¨åŒ¹é…å³å¯ã€‚
    ä¹Ÿä¼šå°è¯•ä»é•¿æ–‡æœ¬ä¸­æå–å·²çŸ¥æ ‡ç­¾å­ä¸²ã€‚

    Args:
        ocr_lines: OCR è¯†åˆ«å‡ºçš„æ–‡å­—è¡Œåˆ—è¡¨
        valid_tags: æ‰€æœ‰åˆæ³•çš„å…¬æ‹›æ ‡ç­¾

    Returns:
        æå–åˆ°çš„æ ‡ç­¾åˆ—è¡¨ï¼ˆå»é‡ï¼‰
    """
    found_tags: list[str] = []
    valid_set = set(valid_tags)

    for line in ocr_lines:
        line = line.strip()
        if not line:
            continue

        # 1. å®Œå…¨åŒ¹é…
        if line in valid_set:
            if line not in found_tags:
                found_tags.append(line)
            continue

        # 2. åˆ«ååŒ¹é…ï¼ˆOCR å¯èƒ½è¯†åˆ«å‡ºåˆ«å/é”™å­—ï¼‰
        mapped = TAG_ALIASES.get(line)
        if mapped and mapped in valid_set:
            if mapped not in found_tags:
                found_tags.append(mapped)
            continue

        # 3. å­ä¸²åŒ¹é…ï¼šåœ¨ OCR è¯†åˆ«çš„é•¿æ–‡æœ¬ä¸­æœç´¢å·²çŸ¥æ ‡ç­¾
        for tag in valid_tags:
            if tag in line and tag not in found_tags:
                found_tags.append(tag)

    return found_tags


def format_results(results: list[dict]) -> str:
    """
    å°†è®¡ç®—ç»“æœæ ¼å¼åŒ–ä¸ºæ–‡æœ¬

    Args:
        results: find_recruit_combinations çš„è¿”å›å€¼

    Returns:
        æ ¼å¼åŒ–çš„æ–‡æœ¬æ¶ˆæ¯
    """
    if not results:
        return "æ²¡æœ‰æ‰¾åˆ°æœ‰ä»·å€¼çš„æ ‡ç­¾ç»„åˆå–µ~\nï¼ˆåªæ˜¾ç¤ºä¿åº• 4â˜… åŠä»¥ä¸Šå’Œ 1â˜… çš„ç»„åˆï¼‰"

    lines = []
    for i, r in enumerate(results):
        tag_str = " + ".join(r["tags"])
        min_star = r["min_rarity"] + 1  # è½¬ä¸º 1-based

        # æ ‡è®°é«˜ä»·å€¼ç»„åˆ
        if min_star >= 5:
            prefix = "ğŸŒŸ"
        elif min_star >= 4:
            prefix = "â­"
        elif min_star == 1:
            prefix = "ğŸ¤–"
        else:
            prefix = "â–ªï¸"

        lines.append(f"{prefix}ã€{tag_str}ã€‘(ä¿åº• {min_star}â˜…)")

        for op in r["operators"]:
            star = rarity_display(op["rarity"])
            lines.append(f"  {star} {op['name']}")

        if i < len(results) - 1:
            lines.append("")

    return "\n".join(lines)
